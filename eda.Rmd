---
title: "EDA Report"
output: html_document
---

## EDA Report

The goal is to understand the overall shape of our data.

```{r Load Data}
library(tidyverse)
library(sf)
library(dplyr)     
library(readr)     
library(lubridate)
library(tidytext)
library(stringr)

inspections <- read_csv("data/inspections_clean.csv") # main dataset
glimpse(inspections)

# check for NAs in key columns
inspections |>
  summarize(
    missing_outcomes = sum(is.na(inspection_outcome)),
    missing_risk = sum(is.na(risk_level_standard)),
    missing_dates = sum(is.na(inspection_date)),
    missing_zips = sum(is.na(zip_code)),
    missing_scores = sum(is.na(inspection_score)) #large number missing here is OK
  )
```

### Basic Plots

```{r Basic Plots}
# Inspections by City
ggplot(inspections, aes(x = city_source)) + geom_bar() + labs(title = "Inspections by City") +  theme_minimal()

library(scales)
#Outcomes
ggplot(inspections, aes(x = inspection_outcome)) + 
  geom_bar() +
  scale_y_continuous(labels = label_comma()) +
  labs(title = "Outcomes")

#Risks
ggplot(inspections, aes(x = risk_level_standard)) + labs(title = "Risks") + geom_bar()
  
### Time Range of the Data

ggplot(inspections_clean, aes(x = inspection_date)) + geom_histogram(bins = 50) + 
scale_y_continuous(labels = label_comma()) +
  labs(title = "Distribution of Inspections Over Time", x = "Date", y = "Count")
```

Our initial phase of exploratory data analysis (EDA) focused on understanding the overall shape, distribution, and integrity of our combined 1.4 million-row dataset. This initial analysis confirms our combined dataset is large, usable, and modern, but critically imbalanced.

Plot 1: Inspections by City This bar chart shows the total number of inspections contributed by each city. The key finding here is that our dataset is heavily imbalanced. Boston is the source of a large majority of our data (over 750,000 rows), while Chicago and New York are similarly sized, and San Francisco is our smallest dataset.

This is a critical finding because it confirms that we cannot use raw counts to compare cities. All future city-to-city comparisons must be based on proportions or percentages (using position = "fill") to be fair and accurate.

Plot 2: Overall Inspection Outcomes This plot shows the distribution of our newly-created inspection_outcome column across the entire dataset. While "Fail" and "Pass" are the most frequent outcomes, this plot is heavily skewed by the disproportionate size of the Boston data. We can't draw any real conclusions from this yet. Its main purpose for now is to confirm that our case_when() logic successfully categorized all 1.4 million rows.

Plot 3: Distribution of Inspections Over Time This histogram is one of our most important initial plots. It confirms two things:

The data is recent: The vast majority of our inspections occurred from roughly 2005 to the present, which is excellent for answering our research questions about modern trends.

We have "bad data" to filter: The plot clearly identifies a small cluster of "bad data" (placeholder dates from 1900) that we must filter out before conducting any time-series analysis. The warning message also confirmed that a negligible number of rows (\~6,400, or \<0.5%) were dropped due to missing dates, which will not impact our analysis.

### City Comparisons

```{r City Comparisons}
#Outcomes by City
ggplot(inspections, aes(x = city_source, fill = inspection_outcome)) + 
  geom_bar(position = "fill") + 
  labs(title = "Outcomes by City", y = "Proportion")

#Risk Level by City
ggplot(inspections, aes(x = city_source, fill = risk_level_standard)) + 
  geom_bar(position = "fill") +
    labs(title = "Risk Level by City", y = "Proportion")

#Score Distributions
ggplot(inspections, aes(x = city_source, y = inspection_score)) + 
  geom_boxplot() +
    labs(title = "Score Distrubutions")

ggplot(inspections, aes(x = inspection_outcome, y = inspection_score, fill = city_source)) +
  geom_boxplot() + 
  facet_wrap(~ city_source) + #show how our standardized Pass/Fail categories line up with the numeric scores
    labs(title = "Score Distributions by City (Standardized")

```

After establishing the overall shape of our data, we drilled down to compare the four cities. This is where our standardization efforts provide their first major insights, revealing that the cities have vastly different inspection profiles.

Plot 4: Proportions of Outcomes by City This plot directly compares the pass/fail rates for each city. We found that Boston and San Francisco have the highest proportion of "Fail" outcomes. In contrast, New York's profile is dominated by "Pass" (reflecting their 'A' grades) and "Pending" results. This confirms that each city's grading system is unique and that our inspection_outcome column successfully captured these differences.

Plot 5: Proportion of Risk Level by City This is one of the most striking findings so far. Chicago and New York log a dramatically higher proportion of "High Risk" violations than Boston and San Francisco. In Chicago, "High Risk" appears to be the most common category, while in Boston, "Low Risk" is dominant. This may reflect different public health definitions of "risk" or different areas of focus for each city's inspectors.

Plot 6 & 7: Score Distributions These two plots (which we've combined for analysis) confirm our inspection_outcome logic and reveal the inverted nature of the scoring systems.

NYC uses a demerit system: A lower score is better. Our plot shows that "Pass" (Grade A) has the lowest scores, while "Fail" (Grade C) has the highest.

SF uses a points-based system: A higher score is better. Our plot confirms this, showing "Pass" (90+) has the highest scores and "Fail" (71-85) has lower scores.

This analysis validates our standardization and proves that the two scoring systems are direct opposites.

### Exploring Fail Rates

```{r Exploring Fail Rates}
# Fail Rate Over Time by City
library(viridis)

# Create a summary table
fails_by_year <- inspections |>
  filter(inspection_date > "2000-01-01") |> # filter out 'bad' dates
  mutate(year = year(inspection_date)) |>
  group_by(city_source, year) |>
  summarize(
    fail_rate = mean(inspection_outcome == "Fail", na.rm = TRUE),
    total_inspections = n()
  ) |>
  filter(total_inspections > 100) # Remove years with tiny data

# Plot the summary
ggplot(fails_by_year, aes(x = year, y = fail_rate, color = city_source)) +
  geom_line(linewidth = 1) +
  geom_point(size = 2) +
  scale_y_continuous(labels = label_percent()) +     # format y-axis as percentage
  scale_color_viridis_d() +                         # add better colors
  labs(
    title = "Fail Rate Over Time by City", 
    y = "Proportion of Fails",                      # <-- Fix y-axis label
    x = "Year",
    color = "City"                                  # <-- Fix legend title
  )

# Least Successful zipcodes in each city in the dataset
fails_by_zip <- inspections |>
  filter(inspection_date > "2000-01-01") |> # Good idea to filter bad dates
  group_by(city_source, zip_code) |>
  summarize(
    fail_rate = mean(inspection_outcome == "Fail", na.rm = TRUE),
    total_inspections = n()
  ) |>
  filter(total_inspections > 100) |> # Only include zips with 100+ inspections
  ungroup()

# Summary table for zip codes
fails_by_zip |>
  group_by(city_source) |>      # Group by city
  top_n(3, fail_rate) |>        # Find the top 3 *within* that city
  ungroup() |>
  
  # This 'reorder_within' is a special trick to make facets work
  mutate(
    zip_code = tidytext::reorder_within(zip_code, fail_rate, city_source)
  ) |>

  ggplot(aes(x = zip_code, y = fail_rate, fill = city_source)) +
  geom_col() +
  tidytext::scale_x_reordered() + # This makes the labels plot correctly
  facet_wrap(~ city_source, scales = "free") + #Create 4 separate charts
  coord_flip() +
  labs(
    title = "Top 3 Zip Codes with Highest Fail Rate by City",
    x = "Zip Code",
    y = "Fail Rate"
  ) +
  theme(legend.position = "none")

```

Following our city-level comparisons, we moved into our first multivariate analysis to answer our research questions about where and when violations occur.

Plot 8: Fail Rate Over Time by City This line graph plots the proportion (percentage) of "Fail" outcomes for each city, from 2008 to 2025. This is our most significant finding so far:

Dramatically Different Systems: The definition of a "Fail" is clearly not standardized.

Boston: Has a very high and consistent "Fail" rate, hovering around 60% for the entire 15-year period. This strongly suggests that Boston's result column logs a "Fail" for even minor infractions, making it a very common outcome.

Chicago: Shows a positive trend. Its fail rate has steadily decreased from \~25% in 2010 to a stable \~18-20% in recent years.

New York: Has an extremely low fail rate, consistently staying below 10%. This aligns perfectly with their "Grade A" system, where a 'C' (which we mapped to "Fail") is rare.

San Francisco: Appears to have a fail rate of around 30%, landing between Boston and the other two cities.

Plot 9: Top 3 Worst Zip Codes by City This bar chart was intended to find the "worst" zip codes across the entire dataset. We have now successfully identified specific geographic areas of concern for each city:

Boston: 02119-3212, 02120

Chicago: 60827, 60619

New York: 11436, 11428

San Francisco: 94134, 94118 \### Boston Zipcodes Map

```{r}

bos_insp <- inspections |>
  filter(city_source == "Boston")
bos <- st_read("Boston Shapefiles/ZIP_Codes.shp")

bos_borders <- bos_shp |> st_union() |>
  st_buffer(.5)
ggplot(bos_borders) +
  geom_sf(data=bos, aes(fill = ZIP5))


# Density map of restaurants per zipcode

rstnt_density <- bos_insp |>
  group_by(zip_code) |>
  summarize(n_restaurants = n_distinct(restaurant_name))

bos <- bos |>
  rename(zip_code = ZIP5)

bos <- left_join(bos, rstnt_density, by = "zip_code")

ggplot(bos_borders) +
  geom_sf(data=bos, aes(fill = n_restaurants))


```

There are 43 zip codes in the City of Boston

## Top Violations Overall

```{r}
inspections |> 
  count(violation_desc, sort = TRUE) |> 
  slice_head(n = 10)
```

We can see here that the top violation found overall from the 4 cities was non-food contact surfaces clean. It's interesting that this is the top as I would have maybe thought it would be violation of food protection since that's what my mind immediately thinks about when it comes to food inspection.

## Days of the week that see the most inspections

```{r}
inspections |> 
  mutate(wday = wday(inspection_date, label = TRUE)) |> 
  count(wday) |>
  ggplot(aes(wday, n)) +
  geom_col() +
  labs(title = "Inspections by Day of Week")
```

As expected we see that inspections do not typically occur on the weekends (Sunday and Saturday) and it seems that inspections closely occur every day during the week but Tuesday seems to have a slightly higher rate.

## Inspection Frequency per Restaurant

```{r}
ggplot(inspections |> count(restaurant_name), aes(n)) +
  geom_histogram(breaks = seq(0, 50, by = 1), color="black", fill="skyblue") +
  labs(title="Distribution of Inspections per Restaurant", x="Number of Inspections", y="Number of Restaurants")
```

In the plot above we can see that are as the number of inspections increase the amount of restaraunts that have that many inspections decrease. This makes sense because if restaurants are consistently failing the food inspection most people won't want to eat their which would affect whether if the business can stay open or not.
