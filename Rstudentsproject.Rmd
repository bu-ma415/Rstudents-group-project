---
title: "R Students Project Notebook"
output:
  html_document:
    df_print: paged
  pdf_document: default
  html_notebook: default
---

### Load Libraries and Data
```{r setup, message=FALSE, warning=FALSE}
library(tidyverse)
library(sf)
library(lubridate)
library(tidytext)
library(scales)
library(viridis)

# Load the single, final clean file
inspections <- read_csv("data/inspections_clean.csv")
```

## EDA Report
The goal of this section is to understand the overall shape of our data, distribution, and integrity of our combined 1.4 million-row dataset (despite the imbalance between records we noted when downloading the dataset).

### Basic Plots
```{r Basic Plots}
# Inspections by City
ggplot(inspections, aes(x = city_source)) + geom_bar() + labs(title = "Inspections by City") + theme_minimal()

#Outcomes
ggplot(inspections, aes(x = inspection_outcome)) + 
  geom_bar() +
  scale_y_continuous(labels = label_comma()) +
  labs(title = "Outcomes")

#Risks
ggplot(inspections, aes(x = risk_level_standard)) + 
  labs(title = "Risks") + 
  scale_y_continuous(labels = label_comma()) + 
  geom_bar()
  
#Time Range of the Data
ggplot(inspections, aes(x = inspection_date)) + geom_histogram(bins = 50) + 
scale_y_continuous(labels = label_comma()) +
  labs(title = "Distribution of Inspections Over Time", x = "Date", y = "Count")
```

The time range plot clearly identifies a small cluster of placeholder dates from 1900 that we must filter out before conducting any time-series analysis. The warning message also confirmed that a negligible number of rows (~6,400, or <0.5%) were dropped due to missing dates, which should not impact our analysis of 1.4 million other records.


### City Comparisons
```{r City Comparisons}
#Outcomes by City
ggplot(inspections, aes(x = city_source, fill = inspection_outcome)) + 
  geom_bar(position = "fill") + 
  labs(title = "Outcomes by City", y = "Proportion")

#Risk Level by City
ggplot(inspections, aes(x = city_source, fill = risk_level_standard)) + 
  geom_bar(position = "fill") +
    labs(title = "Risk Level by City", y = "Proportion")

#Score Distributions
ggplot(inspections, aes(x = city_source, y = inspection_score)) + 
  geom_boxplot() +
    labs(title = "Score Distributions")

ggplot(inspections, aes(x = inspection_outcome, y = inspection_score, fill = city_source)) +
  geom_boxplot() + 
  facet_wrap(~ city_source) + 
    labs(title = "Score Distributions by City (Standardized)")
```
After establishing the overall shape of our data, we drilled down to compare the four cities. This is where our standardization efforts provide their first major insights, revealing that the cities have vastly different inspection profiles.

### Exploring Fail Rates Over Time 
```{r Exploring Fail Rates}
# Create a summary table
fails_by_year <- inspections |>
  filter(inspection_date > "2000-01-01") |> 
  mutate(year = year(inspection_date)) |>
  group_by(city_source, year) |>
  summarize(
    fail_rate = mean(inspection_outcome == "Fail", na.rm = TRUE),
    total_inspections = n()
  ) |>
  filter(total_inspections > 100) 

# Plot the summary
ggplot(fails_by_year, aes(x = year, y = fail_rate, color = city_source)) +
  geom_line(linewidth = 1) +
  geom_point(size = 2) +
  scale_y_continuous(labels = label_percent()) +     
  scale_color_viridis_d() +                         
  labs(
    title = "Fail Rate Over Time by City", 
    y = "Proportion of Fails",                      
    x = "Year",
    color = "City"                                  
  )

# Least Successful zipcodes in each city in the dataset
fails_by_zip <- inspections |>
  filter(inspection_date > "2000-01-01") |> 
  group_by(city_source, zip_code) |>
  summarize(
    fail_rate = mean(inspection_outcome == "Fail", na.rm = TRUE),
    total_inspections = n()
  ) |>
  filter(total_inspections > 100) |> 
  ungroup()

# Summary table for zip codes
fails_by_zip |>
  group_by(city_source) |>      
  top_n(3, fail_rate) |>        
  ungroup() |>
    mutate(
    zip_code = tidytext::reorder_within(zip_code, fail_rate, city_source)
  ) |>

  ggplot(aes(x = zip_code, y = fail_rate, fill = city_source)) +
  geom_col() +
  tidytext::scale_x_reordered() + 
  facet_wrap(~ city_source, scales = "free") + 
  coord_flip() +
  labs(
    title = "Top 3 Zip Codes with Highest Fail Rate by City",
    x = "Zip Code",
    y = "Fail Rate"
  ) +
  theme(legend.position = "none")
```

Following our city-level comparisons, we moved into our first multivariate analysis to answer our research questions about where and when violations occur.


### Days of the week that see the most inspections

```{r Inspections by Day of Week}
inspections |> 
  mutate(wday = wday(inspection_date, label = TRUE)) |> 
  count(wday) |>
  ggplot(aes(wday, n)) +
  geom_col() +
  scale_y_continuous(labels = label_comma()) +
  labs(title = "Inspections by Day of Week")
```

### Inspection Frequency per Restaurant

```{r Inspections per Restaurant}
ggplot(inspections |> count(restaurant_name), aes(n)) +
  geom_histogram(breaks = seq(0, 50, by = 1), color="black", fill="skyblue") +
  labs(title="Distribution of Inspections per Restaurant", x="Number of Inspections", y="Number of Restaurants")
```

The tallest bar shows that nearly 10,000 restaurants have been inspected only once (or close to once) during the dataset's time frame. The number of restaurants drops off steeply for businesses inspected just 2, 3, or 4 times.

## Answering Research Questions

## Gian's Analysis

I would like to investigate the geographic distribution of different
aspects of the health code inspections in Boston. 

We have a restaurant density map already from EDA, but I want to be more
specific and see what the restaurant hotspots are in the city.

```{r hotspot}

# Group by all of the different restaurants, using addresses due to the fact that the same restaurant may be spelled slightly differently by different inspectors.

bos_insp <- inspections |>
  filter(city_source == "Boston")
bos <- st_read("Boston Shapefiles/ZIP_Codes.shp")

bos_borders <- bos |> st_union() |>
  st_buffer(.5)

ind_rsts_old <- bos_insp |>
  distinct(address_full, .keep_all = TRUE) |>
  mutate(coords_clean = str_remove_all(location_string, "[()]"))|>
  separate(coords_clean, into = c("lat", "lon"), sep = ",", convert = T) |>
  mutate (
    lat = as.numeric(lat),
    lon = as.numeric(lon)
  ) |>
  drop_na(lat,lon) |>
  filter(
    lat > 41, lat < 42.8,
    lon > -71.8, lon < -70.7
  ) |>
  select(restaurant_name, address_full, lat, lon)


coords_sf <- ind_rsts_old |>
  st_as_sf(coords = c("lon", "lat"), crs = 4326) |>
  st_transform(26986)


bos <- bos |> 
  st_transform(26986)

df_coords <- as.data.frame(st_coordinates(coords_sf))

my_labels <- c(
  "0 Neighbors",
  "",
  "",
  "",
  "",
  "",
  "",
  "",
  "",
  "70 Neighbors"
)

ggplot() +
  geom_density_2d_filled(
    data = df_coords,
    aes(X, Y, fill = after_stat(level)),
    contour_var = "ndensity",
    alpha = 0.8,
    h = c(500, 500),
    clip = "on"
  ) +
  scale_fill_viridis_d(option = "mako",
                       direction = -1,
                       labels = my_labels) +   
  theme_minimal() +
  labs(title = "City of Boston Restaurant Hotspot Map",
       fill = "Density Scale") +
  geom_sf(data = bos, fill = NA, color = "black", size = 0.05) +
  theme(panel.background = element_rect(fill = "#DEF5E5FF"),
        axis.text = element_blank(),
        theme(axis.title = element_blank()))

```

As we can see, there are hotspots near Harvard Ave in Allston, the North
End, Downtown Crossing, Chinatown, and Newbury St.


**Suburban vs. Urban restaurants**

To make this comparison, we will have to establish rules for what
categorizes a restaurant as rural or urban.

[Urban:]{.underline} Has more than or equal to **10** other restaurants
within a **100 meter** radius.

[Suburban:]{.underline} Has less than **10** other restaurants within a
**100 meter** radius.

```{r urban}

# Create circles around each rst

buffer <- st_buffer(coords_sf$geometry, dist = 100)

int <- st_intersects(buffer, coords_sf |> select(geometry))

# Count how many row joins per buffer

n_int <- lengths(int)

# I want the index of all of the restaurants that have more than x amount of restaurants in this radius

  

ind_rsts <- ind_rsts_old |>
  mutate(
    n_neighbor = n_int - 1,
    urban_yn = (n_int - 1) >= 10
  )

ind_rsts <- st_as_sf(ind_rsts, coords = c("lon", "lat"), crs = 4326)

mean(ind_rsts$urban_yn)
hist(ind_rsts$n_neighbor)

# Now lets plot all of the restaurants with their new designations

ggplot() +
  geom_sf(data = ind_rsts,
          aes(color = urban_yn),
          size = 1,
          alpha = 0.3) +
  geom_sf(data = bos, fill = NA, color = "black") +
  labs(
    title = "All Restaurants Colored By Urban Designation",
    color = ""
  ) +
  scale_color_discrete(
    labels = c("TRUE" = "Urban", "FALSE" = "Suburban")
  )

```

**Hypothesis Tests**

Do urban or suburban restaurants have more failed health inspections? Is
this difference significant?

```{r chisq}

#Expand individual restaurants and their urban/suburban designation to the full inspection report

ind_rsts <- ind_rsts |>
  mutate(
    urban_bucket = (n_int - 1) >= 10
  )


new_bos_insp <- bos_insp |>
  left_join(
    ind_rsts |>
      st_drop_geometry() |>
      select(address_full, urban_yn, n_neighbor),
    by = "address_full"
  ) |>
  filter(
    !if_any(c(urban_yn,viol_status), ~is.na(.))
  )


library("janitor")

new_bos_insp |>
  tabyl(urban_yn, viol_status) |>
  adorn_totals("row") |>
  adorn_percentages("row") |>
  adorn_pct_formatting(digits = 1)


chisq.test(table(new_bos_insp$viol_status, new_bos_insp$urban_yn))


```

This proportion table with marginal proportions shows us that Pass Rate
for Urban restaurants is 0.8% higher than for Suburban restaurants. This
means that suburban restaurants tend to fail health inspections more
often than urban restaurants.

To see whether this result is significant, we can conduct a Chi-Squared
Test for independence. These are the assumptions:

-   Both Urban/Suburban status and Pass/Fail reports must be categorical
    variables with 2+ distinct groups

-   Categories within each designation must be mutually exclusive.

-   Each health inspection report must be independent of the others.

-   There must be more than 5 reports in each of the 4 categories.

With a p-value of 6.969x10\^-10, we can reject the null hypothesis that
the categories are independent from each another. [We have evidence that
Urban/Suburban designation and health inspection pass rates are
dependent on one another.]{.underline}

**Number of Restaurants Within a 100 Meter Radius (Based on IQR)**

Rural: 0-3

Suburban: 4-7

Urban: 8-14

Dense Urban: 15-73

```{r violin}

summary(ind_rsts$n_neighbor)


ggplot() +
  geom_histogram(data = ind_rsts, aes(x=n_neighbor), bins=39) +
  labs(title = "Histogram of Neighbor Restaurants Within a 100 Meter Radius",
       x = "Number of Neighbors",
       y = "Frequency")


vln_data <- bos_insp |>
  drop_na(viol_status) |>
  mutate(viol_status = if_else(viol_status == "Pass", 1, 0)) |>
  group_by(address_full) |>
  summarize(
    pass_rate = mean(viol_status),
    n_inspections = n()
  )

hist(vln_join$log_n_inspections)

# join and add log transform because the distribution of n_inspections shows exponential decay

vln_join <- inner_join(ind_rsts, vln_data, by = "address_full") |>
  mutate(
    log_n_inspections = log(n_inspections),
    trans_n_neighbor = sqrt(n_neighbor)
  )


ggplot(data = vln_join, aes(x = n_neighbor, y = pass_rate)) +
  geom_point(aes(color = log_n_inspections)) +
  geom_smooth(method = "gam",
              formula = y ~ s(x, k = 50),
              se = TRUE,
              fill = "lightgreen",
              alpha = 0.6,
              color = "red2") +
  labs(
    title = "Relationship Between Neighbors and Pass Rate",
    x = "Number of neighbors",
    y = "Pass Rate",
    color = "Inspections Per\nRestaurant"
  ) +
  scale_color_gradient(
    breaks = c(0,
               2,
               4,
               6,
               8),
    labels = c("1",
               "7",
               "55",
               "400",
               "3000")
  )
  




```

This graph corroborates the information we found from the Chi-Squared
test. There is a slight positive trend between the number of neighbors
and the pass rate for health inspections, seen by the positive trend of
the spline. Though slight, we are very confident that this trend exists,
seen by the skinniness of the green prediction band. The band gets
larger as the number of neighbors increases, but the standard error
never exceeds 2.5%. The amount of inspections each restaurant has had
total never does not seem to differ with number of neighbors, but does
differ slightly by pass rate. The larger the number of inspections a
restaurants has, the more they tend to hover around a 50% pass rate.

## Seun's Analysis

### Top Violation Phrases

```{r Top Violation Phrases}
get_bigram_counts <- function(data_chunk) { 
  data_chunk |>
  filter(!is.na(violation_desc)) |>
  unnest_tokens(bigram, violation_desc, token = "ngrams", n = 2) |>
  separate(bigram, c("word1", "word2"), sep = " ") |> 
  anti_join(stop_words, by = c("word1" = "word")) |> 
  anti_join(stop_words, by = c("word2" = "word")) |>
  unite(bigram, word1, word2, sep = " ") |>
  count(bigram, sort = TRUE)
}

#partitioning data into 10 chunks for faster processing time
all_segment_counts <- list()
num_segments <- 10
sample_fraction <- 0.1
for (i in 1:num_segments) {
  message(paste("Processing Segment", i, "of", num_segments))
    data_segment <- inspections |>
    sample_frac(sample_fraction)
    segment_result <- get_bigram_counts(data_segment)
    all_segment_counts[[i]] <- segment_result
}

top_bigrams <- all_segment_counts |>
  bind_rows() |>
  group_by(bigram) |>
  summarize(n = sum(n), .groups = "drop") |>
  arrange(desc(n))

# Plot the top 20
top_bigrams |>
  slice_head(n = 20) |>
  ggplot(aes(x = reorder(bigram, n), y = n)) +
  geom_col() +
  coord_flip() +
  scale_y_continuous(labels=label_number(scale = 1/1000, suffix = "k")) +
  labs(
    title = "Top 20 Specific Violation Phrases (Aggregated Sample)",
    x = "Violation Phrase",
    y = "Total Count (k)"
  )
```
The chart reveals that the most frequent violations found by inspectors are not specific health emergencies but rather structural, maintenance, and sanitation compliance issues. 

### Categorize Violations
```{r Categorize Violations}
inspections_categorized <- inspections |>
  mutate(
    violation_category = case_when(
      str_detect(violation_desc, "mice|rodent|droppings|insects|pests|harborage") ~ "Pest Control",
      str_detect(violation_desc, "temperature|cool|hot-holding|cold-holding|refrigerat") ~ "Food Temperature",
      str_detect(violation_desc, "wash|sanitiz|clean|wiping cloths|dishwashing") ~ "Sanitation & Cleaning",
      str_detect(violation_desc, "hand wash|hygiene|no hair|bare hand") ~ "Employee Hygiene",
      str_detect(violation_desc, "contaminat|cross-contamination|raw|covered|protect") ~ "Cross-Contamination",
      str_detect(violation_desc, "floor|wall|ceiling|plumbing|ventilation|garbage") ~ "Facility/Maintenance",
      TRUE ~ "Other"
    )
  )

#Check new categories
inspections_categorized |>
  count(violation_category, sort = TRUE)
```


### Categorize Restaurants
```{r Categorize Restaurants}
inspections_categorized <- inspections_categorized |>
  mutate(
    # Create one combined description column to search
    desc_all = coalesce(cuisine_description, facility_type, descript) |> tolower(),
    
    restaurant_category = case_when(
      str_detect(desc_all, "pizza|pizzeria") ~ "Pizza",
      str_detect(desc_all, "sushi|japanese") ~ "Sushi/Japanese",
      str_detect(desc_all, "coffee|cafe|bakery|donut") ~ "Coffee/Bakery",
      str_detect(desc_all, "mexican|taco") ~ "Mexican",
      str_detect(desc_all, "chinese") ~ "Chinese",
      str_detect(desc_all, "sandwich|deli|sub") ~ "Sandwich/Deli",
      str_detect(desc_all, "bar|tavern|pub") ~ "Bar/Pub",
      str_detect(desc_all, "restaurant|american") ~ "Restaurant (General)",
      str_detect(desc_all, "school|grocery|market|caterer|kitchen") ~ "Other (Grocery/School/Etc.)",
      TRUE ~ "Other"
    )
  )

#Check new categories
inspections_categorized |>
  count(restaurant_category, sort = TRUE)
```

### Violation "Fingerprint" Plot
```{r Violation "Fingerprint" Plot}
# Ensures bars stack hierarchically (High, Medium, Low)
inspections_categorized <- inspections_categorized |>
  mutate(
    risk_level_standard = factor(
      risk_level_standard, 
      levels = c("High", "Medium", "Low", "Unknown"),
      ordered = TRUE
    )
  )

#Summary table
violation_fingerprint <- inspections_categorized |>
  filter(
    restaurant_category != "Other",
    restaurant_category != "Other (Grocery/School/Etc.)",
    violation_category != "Other"
  ) |>
  count(restaurant_category, violation_category) |>
  group_by(restaurant_category) |>
  mutate(proportion = n / sum(n)) |>
  ungroup()

# Plot the "fingerprint"
ggplot(violation_fingerprint, 
       aes(x = violation_category, y = proportion, fill = violation_category)) +
  geom_col() +
  facet_wrap(~ restaurant_category) + 
  scale_y_continuous(labels = label_percent()) +
  theme(
    axis.text.x = element_blank(),
    axis.ticks.x = element_blank(),
    legend.position = "bottom"
  ) +
  labs(
    title = "Violation 'Fingerprint' by Restaurant Category",
    y = "Proportion of All Violations",
    x = "Violation Type",
    fill = "Violation Category"
  )
```
Restaurant categories do disproportionately receive certain violation types. 
The most important takeaway is that Sanitation & Cleaning (pink) and Pest Control (blue) are the two largest violation categories across nearly all restaurant types. 

### Standardize Inspection Types
```{r Standardize Inspection Types}
inspections_categorized <- inspections_categorized |>
  mutate(
    type_lower = tolower(inspection_type),
    
    inspection_type_standard = case_when(
      # Keywords for complaint
      str_detect(type_lower, "complaint|311|owner complaint") ~ "Complaint",
      
      # Keywords for routine
      str_detect(type_lower, "routine|cycle|canvass|regular") ~ "Routine",
      
      # Keywords for follow-ups
      str_detect(type_lower, "re-inspection|reinspection|follow-up") ~ "Follow-Up",
      
      TRUE ~ "Other"
    )
  )

#new standardized categories
inspections_categorized |>
  count(inspection_type_standard, sort = TRUE)
```

### Plot Severity by Inspection Type
```{r Plot Severity by Inspection Type}
inspections_categorized |>
  filter(
    inspection_type_standard %in% c("Routine", "Complaint"),
    risk_level_standard != "Unknown"
  ) |>
  # NOTE: The mutate is now outside this chunk to save the factor conversion globally.
  ggplot(aes(x = inspection_type_standard, fill = risk_level_standard)) +
  geom_bar(position = "fill") +
  scale_y_continuous(labels = scales::label_percent()) +
  scale_fill_viridis_d(option = "C") +
  labs(
    title = "Violation Severity by Inspection Type",
    x = "Inspection Type",
    y = "Proportion of Violations",
    fill = "Risk Level"
  )
```

The proportional plot clearly shows that Complaint-Driven inspections are more likely to find severe problems than Routine inspections. The proportion of Medium Risk violations is visually larger in the Complaint column than in the Routine column. 

## Plot Violation Type by Inspection Type
```{r Plot Violation Type by Inspection Type}
inspections_categorized |>
  filter(
    inspection_type_standard %in% c("Routine", "Complaint"),
    violation_category != "Other" # Remove 'Other' violations
  ) |>
  ggplot(aes(x = inspection_type_standard, fill = violation_category)) +
  geom_bar(position = "fill") +
  scale_y_continuous(labels = scales::label_percent()) +
  scale_fill_viridis_d() +
  labs(
    title = "Violation Types by Inspection Type",
    x = "Inspection Type",
    y = "Proportion of Violations",
    fill = "Violation Category"
  ) +
  coord_flip() # Flipped axes to make categories easier to read
```

When looking at violation type, Complaint inspections are disproportionately focused on Pest Control and Food Temperature issues. In contrast, Routine inspections find a much higher proportion of Sanitation & Cleaning and Facility/Maintenance problems. This suggests that patrons are quick to report visible signs of pests or temperature issues, while inspectors find more structural/hygiene problems during unannounced, comprehensive checks.


## Arohi's question and analysis

For my analysis, I am focusing on time-series data. As we saw in our Exploratory Data Analysis (EDA), the data is relatively recent, tracing back to around 2005 onwards, which works well for inspecting modern trends.

```{r q1 - Most frequent violations per year}
# Extract years and categorize violations appropriately
inspections_over_time <- inspections |>
  mutate(
    year = year(inspection_date),
    violation_category = case_when(
      str_detect(violation_desc, "mice|rodent|droppings|insects|pests|harborage") ~ "Pest Control",
      str_detect(violation_desc, "temperature|cool|hot-holding|cold-holding|refrigerat") ~ "Food Temperature",
      str_detect(violation_desc, "wash|sanitiz|clean|wiping cloths|dishwashing") ~ "Sanitation & Cleaning",
      str_detect(violation_desc, "hand wash|hygiene|no hair|bare hand") ~ "Employee Hygiene",
      str_detect(violation_desc, "contaminat|cross-contamination|raw|covered|protect") ~ "Cross-Contamination",
      str_detect(violation_desc, "floor|wall|ceiling|plumbing|ventilation|garbage") ~ "Facility/Maintenance",
      TRUE ~ "Other"
    )
  ) |>
  
# Filter out appropriate years due to 1900 "outlier" (no available data between 1900 and 2007)
filter(year >= 2007, year <= 2025)

# Count violations per year and per category
violation_trends <- inspections_over_time |>
  group_by(year, violation_category) |>
  summarise(count = n(), .groups = "drop") |>
  arrange(year, desc(count))

# Most frequent violations per year
most_frequent_by_year <- violation_trends |>
  group_by(year) |>
  slice_max(order_by = count, n = 1) |>
  ungroup()

# Plot
ggplot(violation_trends, aes(x = year, y = count, color = violation_category, group = violation_category)) + 
  geom_line() + 
  geom_point(data = most_frequent_by_year, aes(x = year, y = count)) + 
  scale_color_viridis_d(option = "C") + 
  scale_y_continuous(labels = comma) + 
  scale_x_continuous(
    breaks = seq(2007, 2025, by = 2), 
    labels = seq(2007, 2025, by = 2)
  ) +
  labs(title = "Trends in Most Frequent Violation Categories Over Time", x = "Year", y = "Number of Violations", color = "Violation Category") +
  theme_minimal()
```
We can see that Other is the largest category for most frequent violations per year consistently since the data has been tracked. This makes sense because the tracking methodology is not universal between Boston, NYC, Chicago, and SF, as we found in our EDA, so Other encapsulates all the data inspections unmarked by the categories included.

```{r q2 - Most common violation in 2015 vs 2020}
# Most common violation in 2015 and 2020, for example, to see the effect of environmental circumstances (COVID-19) on violation frequency. 

years_to_compare <- c(2015, 2020)

# Compare top category (which is Other, calculated in our previous code) in each year 
violation_compare <- inspections_over_time |>
  filter(year %in% years_to_compare) |>
  group_by(year, violation_category) |>
  summarise(count = n(), .groups = "drop") |>
  group_by(year) |>
  slice_max(order_by = count, n = 1) |>
  ungroup()

violation_compare

# Plot
ggplot(violation_compare, aes(x = factor(year), y = count, fill = violation_category)) + geom_col() + 
  scale_fill_viridis_d() + 
  labs(title = "Most Common Violation in 2015 vs 2020", x = "Year", y = "Number of Violations", fill = "Top Category") +
  theme_minimal()
```


```{r q3 - All categories within 2015-2020, not just the most common}
# Now, let's take a look at the side by side comparison in all violation categories within 2015 and 2020, not just the top one.

# Count each violation category in each year
violation_compare_all <- inspections_over_time |>
  filter(year %in% years_to_compare) |>
  group_by(year, violation_category) |>
  summarise(count = n(), .groups = "drop")

# Plot 
ggplot(violation_compare_all, aes(x = violation_category, y = count, fill = factor(year))) +
  geom_col(position = "dodge") +
  scale_fill_viridis_d() +
  labs(title = "Violation Categories in 2015 vs 2020", x = "Violation Category", y = "Count", fill = "Year") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

# Calculating which violations grew the most in 2015 vs 2020
violation_diff <- violation_compare_all |>
  pivot_wider(names_from = year, values_from = count, values_fill = 0) |>
  mutate(change = `2020` - `2015`)

violation_diff
```

Interestingly, the Food Temperature and Employee Hygiene categories increased by 85 and 6 counts respectively from 2015 to 2020. While low numbers, these are the only categories that increased in counts. Proportionally, it is especially interesting that Employee Hygiene increased considering it had no violations in 2015 and went up to 6 in 2020. 

```{r q4 - Severity of violations}
# We can also look at the violations from a severity perspective

# Create a variable assigning severity by categories in dataset: Fail, Closed, Violation, Pass, and Other
inspections_over_time <- inspections_over_time |>
  mutate(
    severity = case_when(
      str_detect(tolower(result), "fail") ~ "Fail",
      str_detect(tolower(result), "closed") ~ "Closed",
      str_detect(tolower(result), "violation") ~ "Violation",
      str_detect(tolower(result), "pass") ~ "Pass",
      TRUE ~ "Other"
      )
  )

# Plot
inspections_over_time |>
  filter(year %in% c(2015, 2020)) |>
  ggplot(aes(x = severity, fill = factor(year))) + geom_bar(position = "dodge") +
  labs(title = "Severity of Inspections in 2015 vs 2020", x = "Severity", y = "Count", fill = "Year") +
  theme_minimal()
```

Restaurants under the "Fail" severity category had the second highest count, which is concerning, especially since it exceeded the count of restaurants under the "Pass" severity category. 

```{r q5 - Composition of violations per year}
# How does the composition of all violations change year over year? 

# Plot 
ggplot(violation_trends,aes(x = factor(year), y = count, fill = violation_category)) +
  geom_bar(stat = "identity") + 
  scale_fill_viridis_d(option = "C") + 
  labs(title = "Violation Category Composition by Year", x = "Year", y = "Total Violations", fill = "Category") + 
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```


## Niki's Analysis
### Overall Monthly analysis
```{r Overall Monthly analysis}
# Categorizing the different inspections for later analysis
inspections_cat <- inspections |>
  mutate(
  violation_category = case_when(
      str_detect(violation_desc, "mice|rodent|droppings|insects|pests|harborage") ~ "Pest Control",
      str_detect(violation_desc, "temperature|cool|hot-holding|cold-holding|refrigerat") ~ "Food Temperature",
      str_detect(violation_desc, "wash|sanitiz|clean|wiping cloths|dishwashing") ~ "Sanitation & Cleaning",
      str_detect(violation_desc, "hand wash|hygiene|no hair|bare hand") ~ "Employee Hygiene",
      str_detect(violation_desc, "contaminat|cross-contamination|raw|covered|protect") ~ "Cross-Contamination",
      str_detect(violation_desc, "floor|wall|ceiling|plumbing|ventilation|garbage") ~ "Facility/Maintenance",
      TRUE ~ "Other"
    )
    )
# Adding columns that tell me the month and what season that month correlates to
monthly_season <- inspections_cat|>
  mutate(month = month(inspection_date), season = case_when(
      month %in% c(12, 1, 2) ~ "Winter",
      month %in% c(3, 4, 5) ~ "Spring",
      month %in% c(6, 7, 8) ~ "Summer",
      month %in% c(9, 10, 11) ~ "Fall"
    )
    )|>
  filter(!is.na(month))

# Food Inspection Violations by Month over all cities
month_count <- monthly_season|>
  group_by(month)|>
  summarise(count = n())

ggplot(month_count, aes(x = factor(month), y = count)) +
  geom_col(fill = "steelblue")+
  labs(
    title = "Food Inspection Violations by Month over all cities",
    x = "Month",
    y = "Number of Violations"
  )
```

### Monthly Analysis by City
```{r Monthly Analysis by City}
# Food Inspection Violations by Month for each city
monthly_city_count <- monthly_season|>
  group_by(city_source, month)|>
  summarise(count = n())

ggplot(monthly_city_count) +
  geom_line(aes(x = month, y = count, color = city_source)) +
  scale_x_continuous(breaks = 1:12)+
  labs(
    title = "Food Inspection Violations by Month for each city",
    x = "Month",
    y = "Number of Violations"
  )
```

### Overall Seasonal Analysis
```{r Seasonal Analysis}
# Food Inspection Violations by Seasons over all cities
seasonal_count <- monthly_season|>
  group_by(season)|>
  summarise(count = n())
ggplot(seasonal_count, aes(x = season, y = count)) +
  geom_col(fill = "steelblue")+
  labs(
    title = "Food Inspection Violations by Seasons over all cities",
    x = "Seasons",
    y = "Number of Violations"
  )
```


### Season Analysis by City
```{r Season Analysis by City}
# Food Inspection Violations by Season for each city
seasonal_city_count <- monthly_season|>
  group_by(city_source, season)|>
  summarise(count = n())

ggplot(seasonal_city_count, 
       aes(x = season, y = count, fill = city_source)) +
  geom_col() +
  facet_wrap(~ city_source, nrow = 2) + 
  scale_y_continuous(labels = comma) + 
  labs(
    title = "Food Inspection Violations by Season for each city",
    x = "Season",
    y = "Number of Violations"
  )
```


### Monthly Trends for Each Violation Category
```{r Violations Over Months}
monthly_violation_counts <- monthly_season|>
  filter(!is.na(season),!is.na(violation_category))|>
  group_by(violation_category, month)|>
  summarise(count = n(), .groups = "drop")

ggplot(monthly_violation_counts,
       aes(x = month, y = count, group = violation_category)) +
  geom_line(linewidth = 1.2, color = "steelblue") +
  geom_point() +
  facet_wrap(~ violation_category, scales = "free_y", nrow = 3) +
  scale_x_continuous(breaks = 1:12) +
  theme(
    strip.text = element_text(size = 8)
  ) +
  labs(
    title = "Monthly Trends for Each Violation Category",
    x = "Month",
    y = "Number of Violations"
  )
```

An important exception is Employee Hygiene, which peaks in April rather than October. This may reflect seasonal staffing changes, onboarding of new employees in the spring, or changes in enforcement focus. 

### Seasonal Distribution for Each Violation Category
```{r Violations Over Seasons}
season_violation_counts <- monthly_season|>
  filter(!is.na(season),!is.na(violation_category))|>
  group_by(violation_category, season)|>
  summarise(count = n(), .groups = "drop")

ggplot(season_violation_counts,
       aes(x = season, y = count, fill = season)) +
  geom_col() +
  facet_wrap(~ violation_category, scales = "free_y", nrow = 3) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))+
  labs(
    title = "Seasonal Distribution for Each Violation Category",
    x = "Season",
    y = "Number of Violations"
  )
```

An important exception is Pest Control and Food Temperatrure. Pest control violations peak in the fall, likely because colder outdoor temperatures drive rodents and insects indoors, increasing the risk of infestations in food establishments. 
